{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6956c56f",
   "metadata": {},
   "source": [
    "# Identify Songs by Lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc86c92",
   "metadata": {},
   "source": [
    "This notebook combines notebooks 3 and 4 into one workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d281c41",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de27cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import cv2\n",
    "import easyocr\n",
    "from rapidfuzz import process, fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def734e1",
   "metadata": {},
   "source": [
    "## SETTINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14b85d8",
   "metadata": {},
   "source": [
    "YouTube video URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3440bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUTUBE_URLS = [\n",
    "    \"https://www.youtube.com/watch?v=VpAegQyncmQ\",\n",
    "    \"https://www.youtube.com/watch?v=8ThEhWB-KtQ\",\n",
    "    # \"https://www.youtube.com/watch?v=DW37U-yvd60\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1813e8e0",
   "metadata": {},
   "source": [
    "Initialise path for .env file (located in the parent directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b53db1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "env_path = Path(\"..\") / \".env\"\n",
    "load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba628de0",
   "metadata": {},
   "source": [
    "Data Directories (copied from notebook 01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192a93be",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"..\") / \"data\"  # '..' moves up one level to project root\n",
    "\n",
    "RAW_DATA_DIR = DATA_DIR / \"raw\"\n",
    "CLIPS_DATA_DIR = DATA_DIR / \"clips\"\n",
    "RESULTS_DIR = DATA_DIR / \"results\"\n",
    "\n",
    "STAGING_DIR = CLIPS_DATA_DIR / \"segments\"\n",
    "MUSIC_CLIPS_DIR = CLIPS_DATA_DIR / \"music\"\n",
    "NOT_MUSIC_CLIPS_DIR = CLIPS_DATA_DIR / \"not-music\"\n",
    "\n",
    "# === Create the folders if they don't exist ===\n",
    "RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "STAGING_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MUSIC_CLIPS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "NOT_MUSIC_CLIPS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c203ba",
   "metadata": {},
   "source": [
    "Model directory and filename (copied from notebook 02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf1ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = Path(\"..\") / \"models\"  # '..' moves up one level to project root\n",
    "MODEL_FILENAME = \"music_classifier.pkl\"\n",
    "\n",
    "# === Create the folders if they don't exist ===\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a8e416",
   "metadata": {},
   "source": [
    "Output Audio filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ad7251",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_AUDIO = RAW_DATA_DIR / \"temp_audio.m4a\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb347f8",
   "metadata": {},
   "source": [
    "Output Video filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e7fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_VIDEO = RAW_DATA_DIR / \"temp_video.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caf1561",
   "metadata": {},
   "source": [
    "Clip size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4afe1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_SIZE = 5  # Size of analysis window (seconds) - use same value as in notebook 01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55e9849",
   "metadata": {},
   "source": [
    "Ignore specified warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c1d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\".*pin_memory.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e1c996",
   "metadata": {},
   "source": [
    "## Get Lyrics From Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9106cb",
   "metadata": {},
   "source": [
    "Load Database URL from environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b49be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_URL = os.getenv(\"DB_URL\")\n",
    "\n",
    "if DB_URL:\n",
    "    print(\"Database URL loaded successfully.\")\n",
    "else:\n",
    "    print(\"Error: DB_URL not found. Check your .env file path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0451be9b",
   "metadata": {},
   "source": [
    "Query database to get df_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(DB_URL)\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT song_lyrics.song_id, songs.first_line, song_lyrics.content\n",
    "FROM song_lyrics\n",
    "JOIN songs ON song_lyrics.song_id = songs.id;\n",
    "\"\"\"\n",
    "\n",
    "df_lyrics = pd.read_sql_query(query, engine)\n",
    "df_lyrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd782e76",
   "metadata": {},
   "source": [
    "Filter out lyric anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36c5682",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_lyrics[\"content\"].str.len() > 20\n",
    "df_lyrics = df_lyrics[mask]\n",
    "df_lyrics = df_lyrics.reset_index(drop=True)  # Important for iloc and RapidFuzz matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf4d2a8",
   "metadata": {},
   "source": [
    "Add column for cleaned lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ce798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "df_lyrics[\"cleaned\"] = df_lyrics[\"content\"].apply(clean_text)\n",
    "df_lyrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e734afa",
   "metadata": {},
   "source": [
    "## Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d30b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(MODELS_DIR / MODEL_FILENAME)\n",
    "reader = easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a6b2ba",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db0f030",
   "metadata": {},
   "source": [
    "Print status helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b03fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status(message, width=80):\n",
    "    print(message.ljust(width), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82d006e",
   "metadata": {},
   "source": [
    "Download Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ab8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_audio(output_path: Path, youtube_url: str):\n",
    "    print_status(\"Downloading audio...\")\n",
    "    \n",
    "    command = [\n",
    "        \"yt-dlp\",\n",
    "        \"-q\",\n",
    "        \"--force-overwrites\",\n",
    "        \"-f\", \"bestaudio[ext=m4a]/bestaudio\",\n",
    "        \"-o\", str(output_path),\n",
    "        youtube_url,\n",
    "    ]\n",
    "\n",
    "    subprocess.run(command, check=True)\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def download_video(output_path: Path, youtube_url: str):\n",
    "    print_status(\"Downloading video...\")\n",
    "    \n",
    "    command = [\n",
    "        \"yt-dlp\",\n",
    "        \"-q\",\n",
    "        \"--force-overwrites\",\n",
    "        \"-f\", \"bestvideo[ext=mp4]\",\n",
    "        \"-o\", str(output_path),\n",
    "        youtube_url,\n",
    "    ]\n",
    "\n",
    "    subprocess.run(command, check=True)\n",
    "\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b55105",
   "metadata": {},
   "source": [
    "Audio Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d7f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_music_blocks(df, save_plot_path=None):\n",
    "\n",
    "    df_plot = df.copy()\n",
    "\n",
    "    # 1. Prepare data for plotting\n",
    "    # Convert labels to numbers (1 for music, 0 for not-music)\n",
    "    df_plot[\"label_num\"] = df_plot[\"label\"].map({\"music\": 1, \"not-music\": 0})\n",
    "\n",
    "    # 2. Setup the plot\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.step(\n",
    "        df_plot[\"start_sec\"] / 60,\n",
    "        df_plot[\"label_num\"],\n",
    "        where=\"post\",\n",
    "        color=\"teal\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "\n",
    "    # 3. Formatting\n",
    "    plt.fill_between(\n",
    "        df_plot[\"start_sec\"] / 60,\n",
    "        df_plot[\"label_num\"],\n",
    "        step=\"post\",\n",
    "        alpha=0.3,\n",
    "        color=\"teal\",\n",
    "    )\n",
    "    plt.yticks([0, 1], [\"Not-Music\", \"Music\"])\n",
    "    plt.xlabel(\"Time (Minutes)\")\n",
    "    plt.ylabel(\"Classification\")\n",
    "    plt.title(\"Music Detection Timeline\")\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_plot_path:\n",
    "        plt.savefig(save_plot_path, dpi=300, bbox_inches=\"tight\")\n",
    "        print(f\"Plot saved to: {save_plot_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def generate_music_timeline(file_path, window_sec, model, sr=22050):\n",
    "    total_duration = _get_duration(file_path)\n",
    "    total_chunks = int(total_duration // window_sec)\n",
    "\n",
    "    # Calculate bytes per chunk: (seconds * rate * 4 bytes for float32)\n",
    "    bytes_per_chunk = window_sec * sr * 4\n",
    "    results = []\n",
    "\n",
    "    # Use FFmpeg to pipe RAW PCM data to Python\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\",\n",
    "        file_path,\n",
    "        \"-f\",\n",
    "        \"f32le\",\n",
    "        \"-acodec\",\n",
    "        \"pcm_f32le\",\n",
    "        \"-ar\",\n",
    "        str(sr),\n",
    "        \"-ac\",\n",
    "        \"1\",\n",
    "        \"-\",\n",
    "    ]\n",
    "\n",
    "    process = subprocess.Popen(\n",
    "        command, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL\n",
    "    )\n",
    "\n",
    "    chunk_idx = 0\n",
    "    while True:\n",
    "        raw_bytes = process.stdout.read(bytes_per_chunk)\n",
    "        if not raw_bytes or len(raw_bytes) < bytes_per_chunk:\n",
    "            break\n",
    "\n",
    "        # Convert bytes to numpy\n",
    "        y_block = np.frombuffer(raw_bytes, dtype=np.float32)\n",
    "\n",
    "        # --- FEATURE EXTRACTION ---\n",
    "        mfccs = librosa.feature.mfcc(y=y_block, sr=sr, n_mfcc=13)\n",
    "        mfccs_mean = np.mean(mfccs.T, axis=0)\n",
    "        mfccs_std = np.std(mfccs.T, axis=0)\n",
    "        centroid = librosa.feature.spectral_centroid(y=y_block, sr=sr)\n",
    "        centroid_mean = np.mean(centroid)\n",
    "\n",
    "        features = np.hstack([mfccs_mean, mfccs_std, centroid_mean]).reshape(1, -1)\n",
    "\n",
    "        # --- PREDICTION ---\n",
    "        pred_idx = model.predict(features)[0]\n",
    "        prob = np.max(model.predict_proba(features))\n",
    "\n",
    "        start_time = chunk_idx * window_sec\n",
    "        results.append(\n",
    "            {\n",
    "                \"start_sec\": start_time,\n",
    "                \"end_sec\": start_time + window_sec,\n",
    "                \"label\": \"music\" if pred_idx == 1 else \"not-music\",\n",
    "                \"confidence\": round(prob, 4),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        chunk_idx += 1\n",
    "\n",
    "        # --- DISPLAY PERCENTAGE UPDATE ---\n",
    "        if (chunk_idx % 20 == 0) or (chunk_idx == total_chunks):\n",
    "            percent = int((chunk_idx / total_chunks) * 100)\n",
    "            # Limits display to 100% and prints on one line\n",
    "            print_status(\n",
    "                f\"Generating Music Timeline: {min(100, percent):>3}% complete\"\n",
    "            )\n",
    "\n",
    "    process.terminate()\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def _get_duration(file_path):\n",
    "    cmd = [\n",
    "        \"ffprobe\",\n",
    "        \"-v\",\n",
    "        \"error\",\n",
    "        \"-show_entries\",\n",
    "        \"format=duration\",\n",
    "        \"-of\",\n",
    "        \"default=noprint_wrappers=1:nokey=1\",\n",
    "        file_path,\n",
    "    ]\n",
    "    return float(subprocess.check_output(cmd))\n",
    "\n",
    "\n",
    "def extract_music_blocks(df, min_duration_sec=120, max_gap_seconds=15):\n",
    "    print_status(\"Extracting music blocks...\")\n",
    "    \n",
    "    # Create a copy so we don't overwrite the original dataframe\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # 1. Convert to numeric for processing\n",
    "    df_clean[\"is_music\"] = df_clean[\"label\"].map({\"music\": 1, \"not-music\": 0})\n",
    "\n",
    "    # 2. SMOOTHING: Median filter - requires at least 2/3 chunks to match.\n",
    "    df_clean[\"is_music\"] = (\n",
    "        df_clean[\"is_music\"]\n",
    "        .rolling(window=3, center=True)\n",
    "        .median()\n",
    "        .fillna(df_clean[\"is_music\"])\n",
    "    )\n",
    "\n",
    "    # 3. BRIDGE GAPS: check if music exists within the 'max_gap' range\n",
    "    # Treat \"not-music\" sections as \"music\" if shorter than max_gap_seconds,\n",
    "    gap_chunks = max_gap_seconds // CLIP_SIZE\n",
    "    df_clean[\"is_music\"] = (\n",
    "        df_clean[\"is_music\"]\n",
    "        .rolling(window=gap_chunks, center=True, min_periods=1)\n",
    "        .max()\n",
    "    )\n",
    "\n",
    "    # 4. Identify song blocks using cumsum logic\n",
    "    df_clean[\"block_id\"] = (\n",
    "        df_clean[\"is_music\"] != df_clean[\"is_music\"].shift()\n",
    "    ).cumsum()\n",
    "\n",
    "    # 5. Group and Aggregate\n",
    "    blocks = df_clean.groupby(\"block_id\").agg(\n",
    "        {\"is_music\": \"first\", \"start_sec\": \"min\", \"end_sec\": \"max\"}\n",
    "    )\n",
    "\n",
    "    blocks[\"duration\"] = blocks[\"end_sec\"] - blocks[\"start_sec\"]\n",
    "\n",
    "    # 6. Filter by music label (1) and min_duration threshold\n",
    "    songs = blocks[\n",
    "        (blocks[\"is_music\"] == 1) & (blocks[\"duration\"] >= min_duration_sec)\n",
    "    ].copy()\n",
    "\n",
    "    # Formatting helper\n",
    "    def format_time(seconds):\n",
    "        return f\"{int(seconds // 60):02d}:{int(seconds % 60):02d}\"\n",
    "\n",
    "    songs[\"start_timestamp\"] = songs[\"start_sec\"].apply(format_time)\n",
    "    songs[\"end_timestamp\"] = songs[\"end_sec\"].apply(format_time)\n",
    "\n",
    "    songs = songs.reset_index()  # moves block_id from index to column\n",
    "\n",
    "    return songs[\n",
    "        [\n",
    "            \"block_id\",\n",
    "            \"start_timestamp\",\n",
    "            \"end_timestamp\",\n",
    "            \"start_sec\",\n",
    "            \"end_sec\",\n",
    "            \"duration\",\n",
    "        ]\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b459cb98",
   "metadata": {},
   "source": [
    "Video Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4029cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_song_blocks(music_blocks, file_path, youtube_url, debug=False):\n",
    "\n",
    "    print_status(\"Populating song blocks...\")\n",
    "\n",
    "    # Load video capture\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "\n",
    "    # Define video properties\n",
    "    # fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    lyric_start_row = int(height * 0.6)\n",
    "    lyric_end_row   = height\n",
    "\n",
    "    SHIFT_TIME = 30  # In case lyrics aren't showing at start and end of song\n",
    "\n",
    "    song_blocks = {}\n",
    "    for _, row in music_blocks.iterrows():\n",
    "        block_id = row['block_id']\n",
    "        block_start_time = row['start_sec']\n",
    "        block_end_time = row['end_sec']\n",
    "        \n",
    "        song_blocks[block_id] = []\n",
    "        \n",
    "        song_start_time = block_start_time\n",
    "        song_start_time_shifted = song_start_time + SHIFT_TIME\n",
    "        block_end_time_shifted = block_end_time - SHIFT_TIME\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"\\n--- Processing Music Block: {block_start_time}s to {block_end_time}s ---\")\n",
    "\n",
    "        # Get song_id at end (once)\n",
    "        song_id_end = None\n",
    "        while (song_id_end is None) and (block_end_time_shifted > block_start_time):\n",
    "            song_end = _get_best_matching_song(cap, lyric_start_row, lyric_end_row, width, block_end_time_shifted, debug=debug)\n",
    "            if not song_end:\n",
    "                block_end_time_shifted -= SHIFT_TIME # Shift back if nothing found\n",
    "                continue\n",
    "            song_id_end = song_end[\"id\"]\n",
    "        if song_id_end is None:\n",
    "            if debug:\n",
    "                print(\"NO SONG FOUND IN THIS SONG BLOCK\")\n",
    "            continue\n",
    "        \n",
    "        # ===== GET SONG(S) IN SONG BLOCK =====\n",
    "        while song_start_time_shifted < block_end_time_shifted:\n",
    "\n",
    "            # Get song_id at start of song\n",
    "            song_id_start = None\n",
    "            while (song_id_start is None) and (song_start_time_shifted < block_end_time_shifted):\n",
    "                song_start = _get_best_matching_song(cap, lyric_start_row, lyric_end_row, width, song_start_time_shifted, debug=debug)\n",
    "                if not song_start:\n",
    "                    song_start_time_shifted += SHIFT_TIME # Shift forward if nothing found\n",
    "                    continue\n",
    "                song_id_start = song_start[\"id\"]\n",
    "                song_first_line_start = song_start[\"first_line\"]\n",
    "            if song_id_start is None:\n",
    "                if debug:\n",
    "                    print(\"NO SONG FOUND IN THIS SONG BLOCK\")\n",
    "                break\n",
    "\n",
    "            # Check if song covers rest of song block\n",
    "            if song_id_start == song_id_end:\n",
    "                if debug:\n",
    "                    print(f\"SONG COMPLETED: {song_start}\")\n",
    "                \n",
    "                song_blocks[block_id].append({\n",
    "                    \"id\": song_id_start,\n",
    "                    \"first_line\": song_first_line_start,\n",
    "                    \"start\": song_start_time,\n",
    "                    \"end\": block_end_time,\n",
    "                    \"start_format\": _format_timestamp(song_start_time),\n",
    "                    \"end_format\": _format_timestamp(block_end_time),\n",
    "                    \"link\": f\"{youtube_url}&t={song_start_time}\",\n",
    "                    })\n",
    "                break # Entire block is one song, we are done with this block\n",
    "\n",
    "            # ============= Multiple songs in song block =============\n",
    "            if debug:\n",
    "                print(f\"MULTIPLE SONGS IN BLOCK - commence binary search..\")\n",
    "\n",
    "            # Binary search for the transition point\n",
    "            end_time = _get_song_end_time(song_start_time_shifted, block_end_time_shifted, lyric_start_row, lyric_end_row, width, song_id_start, cap, debug=debug)\n",
    "\n",
    "            # Assume delay in changing lyrics to new song\n",
    "            end_time -= 5\n",
    "\n",
    "            if debug:\n",
    "                print(f\"SONG COMPLETED: {song_start}\")\n",
    "\n",
    "            song_blocks[block_id].append({\n",
    "                \"id\": song_id_start,\n",
    "                \"first_line\": song_first_line_start,\n",
    "                \"start\": song_start_time,\n",
    "                \"end\": end_time,\n",
    "                \"start_format\": _format_timestamp(song_start_time),\n",
    "                \"end_format\": _format_timestamp(end_time),\n",
    "                \"link\": f\"{youtube_url}&t={song_start_time}\",\n",
    "                })\n",
    "            \n",
    "            song_start_time = end_time  # Move to the start of the next song\n",
    "            song_start_time_shifted = song_start_time + SHIFT_TIME\n",
    "\n",
    "    cap.release()\n",
    "    return song_blocks\n",
    "\n",
    "\n",
    "def _format_timestamp(seconds: int) -> str:\n",
    "    h, r = divmod(int(seconds), 3600)\n",
    "    m, s = divmod(r, 60)\n",
    "    return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
    "\n",
    "\n",
    "def _identify_songs_from_lyrics(search_text, df_lyrics, threshold=80):\n",
    "    search_text_cleaned = clean_text(search_text)\n",
    "    \n",
    "    if not search_text_cleaned or len(search_text_cleaned) < 10:\n",
    "        return []\n",
    "\n",
    "    # extract returns a list of (string, score, index) tuples\n",
    "    results = process.extract(\n",
    "        search_text_cleaned, \n",
    "        df_lyrics['cleaned'], \n",
    "        scorer=fuzz.partial_ratio,\n",
    "        # scorer=fuzz.token_set_ratio,  # could try this instead\n",
    "        score_cutoff=threshold,\n",
    "        limit=5 \n",
    "    )\n",
    "\n",
    "    matches = []\n",
    "    for _, score, idx in results:\n",
    "        match_row = df_lyrics.iloc[idx]\n",
    "        matches.append({\n",
    "            \"id\": int(match_row[\"song_id\"]),\n",
    "            \"first_line\": match_row[\"first_line\"],\n",
    "            \"score\": round(float(score), 1)\n",
    "        })\n",
    "\n",
    "    # RapidFuzz's extract automatically sorts by score DESC\n",
    "    return matches\n",
    "\n",
    "\n",
    "def _display_images(lyric_zone, thresh):\n",
    "    \"\"\"View original image frame and formatted frame seen by OCR\"\"\"\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    ax[0].imshow(cv2.cvtColor(lyric_zone, cv2.COLOR_BGR2RGB))\n",
    "    ax[0].set_title(\"Original Crop\")\n",
    "\n",
    "    ax[1].imshow(thresh, cmap='gray')\n",
    "    ax[1].set_title(\"Thresholded (OCR Input)\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def _get_screen_text(frame, lyric_start_row, lyric_end_row, width, debug):\n",
    "    \"\"\"Return text shown on specified region of screen\"\"\"\n",
    "    \n",
    "    # 1. CROP: Keep only the bottom section\n",
    "    lyric_zone = frame[lyric_start_row:lyric_end_row, 0:width]\n",
    "\n",
    "    # 2. GRAYSCALE: Process only the small cropped area\n",
    "    gray_lyric = cv2.cvtColor(lyric_zone, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 3. THRESHOLD: High Contrast (Makes OCR 2x more accurate)\n",
    "    _, thresh = cv2.threshold(gray_lyric, 200, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # 4. OCR: read lyrics\n",
    "    results = reader.readtext(thresh, detail=0)\n",
    "    if not results:\n",
    "        if debug:\n",
    "            _display_images(lyric_zone, thresh)\n",
    "        return None\n",
    "\n",
    "    # 5. FORMAT: convert from list to string\n",
    "    text = \" \".join(results)    \n",
    "    if len(text) < 20:  # catch random noise or too few lyrics\n",
    "        return None\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def _get_song_end_time(left, right, lyric_start_row, lyric_end_row, width, song_id, cap, debug):\n",
    "    \"\"\"Binary search for time when changes from one song to another\"\"\"\n",
    "\n",
    "    while (right - left) > 2:  # Stop when within 2 seconds\n",
    "        mid = (left + right) // 2\n",
    "        \n",
    "        song = _get_best_matching_song(cap, lyric_start_row, lyric_end_row, width, mid, debug=debug)\n",
    "        if not song:\n",
    "            # Catch no song match (e.g. lyrics not displayed on screen)\n",
    "            right = right - 10\n",
    "            continue\n",
    "        \n",
    "        mid_id = song[\"id\"]\n",
    "\n",
    "        if mid_id == song_id:\n",
    "            left = mid\n",
    "        else:\n",
    "            right = mid\n",
    "\n",
    "    return left\n",
    "\n",
    "\n",
    "def _get_best_matching_song(cap, lyric_start_row, lyric_end_row, width, sec, debug):\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, sec * 1000)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        return None\n",
    "\n",
    "    text = _get_screen_text(frame, lyric_start_row, lyric_end_row, width, debug=debug)\n",
    "    songs = _identify_songs_from_lyrics(text, df_lyrics)\n",
    "    \n",
    "    if not songs:\n",
    "        if debug:\n",
    "            print(f\"{sec}s: NO MATCH FOUND: text={text}\")\n",
    "        return None\n",
    "\n",
    "    return songs[0]\n",
    "\n",
    "\n",
    "def display_song_block_summary(song_blocks):\n",
    "    for block_id in song_blocks.keys():\n",
    "        print(\"---\".ljust(80))\n",
    "        for song in song_blocks[block_id]:\n",
    "            print(f\"{song[\"start_format\"]} - {song[\"link\"]} - {song[\"first_line\"]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ac3816",
   "metadata": {},
   "source": [
    "## Run Main Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e78ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_urls = len(YOUTUBE_URLS)\n",
    "\n",
    "for i, url in enumerate(YOUTUBE_URLS, 1):\n",
    "    \n",
    "    print(f\"\\n### Video {i} of {len_urls} ###\")\n",
    "\n",
    "    # ===== AUDIO =====\n",
    "    tmp_audio = download_audio(output_path=OUTPUT_AUDIO, youtube_url=url)\n",
    "    df_blocks = generate_music_timeline(file_path=tmp_audio, window_sec=CLIP_SIZE, model=model)\n",
    "    # plot_music_blocks(df=df_blocks)\n",
    "    music_blocks = extract_music_blocks(df_blocks, min_duration_sec=120, max_gap_seconds=15)\n",
    "\n",
    "    # ===== VIDEO =====\n",
    "    tmp_video = download_video(output_path=OUTPUT_VIDEO, youtube_url=url)\n",
    "    song_blocks = populate_song_blocks(file_path=tmp_video, music_blocks=music_blocks, youtube_url=url)\n",
    "    display_song_block_summary(song_blocks)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
