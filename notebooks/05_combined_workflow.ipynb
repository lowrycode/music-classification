{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6956c56f",
   "metadata": {},
   "source": [
    "# Identify Songs by Lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc86c92",
   "metadata": {},
   "source": [
    "This notebook combines notebooks 3 and 4 into one workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d281c41",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de27cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import cv2\n",
    "import easyocr\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def734e1",
   "metadata": {},
   "source": [
    "## CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1813e8e0",
   "metadata": {},
   "source": [
    "Initialise path for .env file (located in the parent directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b53db1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "env_path = Path(\"..\") / \".env\"\n",
    "load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba628de0",
   "metadata": {},
   "source": [
    "Data Directories (copied from notebook 01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192a93be",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"..\") / \"data\"  # '..' moves up one level to project root\n",
    "\n",
    "RAW_DATA_DIR = DATA_DIR / \"raw\"\n",
    "CLIPS_DATA_DIR = DATA_DIR / \"clips\"\n",
    "RESULTS_DIR = DATA_DIR / \"results\"\n",
    "\n",
    "STAGING_DIR = CLIPS_DATA_DIR / \"segments\"\n",
    "MUSIC_CLIPS_DIR = CLIPS_DATA_DIR / \"music\"\n",
    "NOT_MUSIC_CLIPS_DIR = CLIPS_DATA_DIR / \"not-music\"\n",
    "\n",
    "# === Create the folders if they don't exist ===\n",
    "RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "STAGING_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MUSIC_CLIPS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "NOT_MUSIC_CLIPS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c203ba",
   "metadata": {},
   "source": [
    "Model directory and filename (copied from notebook 02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf1ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = Path(\"..\") / \"models\"  # '..' moves up one level to project root\n",
    "MODEL_FILENAME = \"music_classifier.pkl\"\n",
    "\n",
    "# === Create the folders if they don't exist ===\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a8e416",
   "metadata": {},
   "source": [
    "Output Audio filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ad7251",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_AUDIO = RAW_DATA_DIR / \"temp_audio.m4a\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb347f8",
   "metadata": {},
   "source": [
    "Output Video filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e7fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_VIDEO = RAW_DATA_DIR / \"temp_video.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caf1561",
   "metadata": {},
   "source": [
    "Clip size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4afe1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_SIZE = 5  # Size of analysis window (seconds) - use same value as in notebook 01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55975676",
   "metadata": {},
   "source": [
    "YouTube settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47278da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUTUBE_API_KEY = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "YOUTUBE_BASE_URL = \"https://www.youtube.com/watch?v=\"\n",
    "\n",
    "NEWLAND_CHANNEL_ID = \"UCQ0k5yqN9gikrGiCG8Y3UBQ\"\n",
    "RIVERSIDE_CHANNEL_ID = \"UCS_Q5G3O5fydsvRc-uoOanQ\"\n",
    "HESSLE_CHANNEL_ID = \"UCl4soOZzigl4RwGWplFmvOw\"\n",
    "ORCHARD_PARK_CHANNEL_ID = \"UCIARZq9myh9SrNneKRx5GtA\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55e9849",
   "metadata": {},
   "source": [
    "Ignore specified warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c1d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\".*pin_memory.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55807104",
   "metadata": {},
   "source": [
    "## SETTINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5453dc84",
   "metadata": {},
   "source": [
    "YouTube Search Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebacaeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_channel_id = NEWLAND_CHANNEL_ID  # Search channel\n",
    "youtube_q = \"Service\"  # Search query\n",
    "filter_keywords_in_title = [\"Newland\", \"Morning\"]\n",
    "\n",
    "# Recommend time window < 3 months to ensure no videos are missed\n",
    "published_after = \"2023-12-17T00:00:00Z\"\n",
    "published_before = \"2023-12-19T00:00:00Z\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be385f5c",
   "metadata": {},
   "source": [
    "Variables for inserting into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0462ffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "church_activity_id = 1  # 1: Newland, 2: Network  (check df_activities for others)\n",
    "link_title_PREFIX = \"Newland AM\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911df933",
   "metadata": {},
   "source": [
    "Prevent costly song identification if existing links are found for same activity within close proximity to date. --- **WARNING:** can skip songs if service is split into two or more videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31afb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIP_IF_LINKS_MAY_EXIST = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e1c996",
   "metadata": {},
   "source": [
    "## Get Data From Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9106cb",
   "metadata": {},
   "source": [
    "Load Database URL and Create Database Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b49be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "DB_URL = os.getenv(\"DB_URL\")\n",
    "engine = create_engine(DB_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220ce351",
   "metadata": {},
   "source": [
    "### Church Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2bf9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM church_activities;\"\n",
    "\n",
    "df_activities = pd.read_sql_query(query, engine)\n",
    "df_activities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263e2c47",
   "metadata": {},
   "source": [
    "### Lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0451be9b",
   "metadata": {},
   "source": [
    "Query database to get df_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT song_lyrics.song_id, songs.first_line, song_lyrics.content\n",
    "FROM song_lyrics\n",
    "JOIN songs ON song_lyrics.song_id = songs.id;\n",
    "\"\"\"\n",
    "\n",
    "df_lyrics = pd.read_sql_query(query, engine)\n",
    "df_lyrics.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd782e76",
   "metadata": {},
   "source": [
    "Filter out lyric anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36c5682",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_lyrics[\"content\"].str.len() > 20\n",
    "df_lyrics = df_lyrics[mask]\n",
    "df_lyrics = df_lyrics.reset_index(drop=True)  # Important for iloc and RapidFuzz matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf4d2a8",
   "metadata": {},
   "source": [
    "Add column for cleaned lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ce798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "df_lyrics[\"cleaned\"] = df_lyrics[\"content\"].apply(clean_text)\n",
    "df_lyrics.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20f8d15",
   "metadata": {},
   "source": [
    "### Song Usages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7e8861",
   "metadata": {},
   "source": [
    "Query database to get df_usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19d391",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    su.id, \n",
    "    su.song_id, \n",
    "    su.used_date, \n",
    "    su.church_activity_id,\n",
    "    STRING_AGG(syl.id || ':' || syl.start_seconds, ',') as existing_links\n",
    "FROM song_usage su\n",
    "LEFT JOIN song_youtube_links syl ON su.id = syl.song_usage_id\n",
    "GROUP BY su.id, su.song_id, su.used_date, su.church_activity_id\n",
    "\"\"\"\n",
    "df_usages = pd.read_sql_query(query, engine)\n",
    "\n",
    "# Convert \"id:time,id:time\" into a list of dicts: [{'id': 1, 't': 300}, ...]\n",
    "def parse_links(x):\n",
    "    if pd.isna(x): return []\n",
    "    return [{\"id\": int(i.split(':')[0]), \"t\": int(i.split(':')[1])} for i in x.split(',')]\n",
    "\n",
    "df_usages['existing_links'] = df_usages['existing_links'].apply(parse_links)\n",
    "df_usages.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025059b2",
   "metadata": {},
   "source": [
    "Create index for fast lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3779cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usages_lookup = df_usages.set_index(['song_id', 'used_date', 'church_activity_id']).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1e31b8",
   "metadata": {},
   "source": [
    "## Get YouTube Videos (uses API)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cae236c",
   "metadata": {},
   "source": [
    "Query YouTube Videos using API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8cc716",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)\n",
    "\n",
    "request = youtube.search().list(\n",
    "    part=\"snippet\",\n",
    "    q=youtube_q,\n",
    "    channelId=youtube_channel_id,\n",
    "    type=\"video\",\n",
    "    publishedAfter=published_after,\n",
    "    publishedBefore=published_before,\n",
    "    maxResults=50,\n",
    "    order=\"date\",\n",
    ")\n",
    "response = request.execute()\n",
    "\n",
    "# Sort the items list in-place by the 'publishedAt' string\n",
    "# Since ISO dates (YYYY-MM-DD) sort correctly alphabetically, this works fine\n",
    "response['items'].sort(key=lambda x: x['snippet']['publishedAt'])\n",
    "\n",
    "results_count = len(response['items'])\n",
    "print(results_count)\n",
    "if results_count >= 50:\n",
    "    print(\"❗WARNING: reached maximum results count - some videos may have been missed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0901ce",
   "metadata": {},
   "source": [
    "Build youtube_videos (list of dictionaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b530d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_videos = [\n",
    "    {\n",
    "        \"url\": f\"{YOUTUBE_BASE_URL}{item[\"id\"][\"videoId\"]}\",\n",
    "        \"title\": item[\"snippet\"][\"title\"],\n",
    "        \"date\": datetime.fromisoformat(item[\"snippet\"][\"publishedAt\"].replace(\"Z\", \"+00:00\")).date(),\n",
    "        \"church_activity_id\": church_activity_id,\n",
    "    } for item in response[\"items\"]\n",
    "    ]\n",
    "print(f\"{len(youtube_videos)} videos match search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0224dc1b",
   "metadata": {},
   "source": [
    "Filter youtube_videos by keyword in title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2657df40",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_videos = [\n",
    "    v for v in youtube_videos \n",
    "    if any(kw.lower() in v[\"title\"].lower() for kw in filter_keywords_in_title)\n",
    "]\n",
    "print(f\"{len(youtube_videos)} videos match keyword filters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e734afa",
   "metadata": {},
   "source": [
    "## Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d30b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(MODELS_DIR / MODEL_FILENAME)\n",
    "reader = easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a6b2ba",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db0f030",
   "metadata": {},
   "source": [
    "Generic helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b03fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status(message, width=80):\n",
    "    print(message.ljust(width), end=\"\\r\")\n",
    "\n",
    "\n",
    "def _get_dates_to_try(target_date):\n",
    "    # YouTube video date might be late by up to 2 days\n",
    "    return [target_date, target_date - timedelta(days=1), target_date - timedelta(days=2)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82d006e",
   "metadata": {},
   "source": [
    "Download Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ab8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_audio(output_path: Path, youtube_url: str):\n",
    "    print_status(\"Downloading audio...\")\n",
    "    \n",
    "    command = [\n",
    "        \"yt-dlp\",\n",
    "        \"-q\",\n",
    "        \"--force-overwrites\",\n",
    "        \"-f\", \"wa[ext=m4a]/wa/ba\",\n",
    "        \"--extract-audio\",\n",
    "        \"--audio-format\", \"m4a\",\n",
    "        \"-o\", str(output_path),\n",
    "        youtube_url,\n",
    "    ]\n",
    "\n",
    "    subprocess.run(command, check=True)\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def download_video(output_path: Path, youtube_url: str):\n",
    "    print_status(\"Downloading video...\")\n",
    "    \n",
    "    command = [\n",
    "        \"yt-dlp\",\n",
    "        \"-q\",\n",
    "        \"--force-overwrites\",\n",
    "        \"-f\", \"bv*[height<=480][ext=mp4]/wv*[ext=mp4]\",\n",
    "        \"-o\", str(output_path),\n",
    "        youtube_url,\n",
    "    ]\n",
    "\n",
    "    subprocess.run(command, check=True)\n",
    "\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b55105",
   "metadata": {},
   "source": [
    "Audio Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d7f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_music_blocks(df, save_plot_path=None):\n",
    "\n",
    "    df_plot = df.copy()\n",
    "\n",
    "    # 1. Prepare data for plotting\n",
    "    # Convert labels to numbers (1 for music, 0 for not-music)\n",
    "    df_plot[\"label_num\"] = df_plot[\"label\"].map({\"music\": 1, \"not-music\": 0})\n",
    "\n",
    "    # 2. Setup the plot\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.step(\n",
    "        df_plot[\"start_sec\"] / 60,\n",
    "        df_plot[\"label_num\"],\n",
    "        where=\"post\",\n",
    "        color=\"teal\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "\n",
    "    # 3. Formatting\n",
    "    plt.fill_between(\n",
    "        df_plot[\"start_sec\"] / 60,\n",
    "        df_plot[\"label_num\"],\n",
    "        step=\"post\",\n",
    "        alpha=0.3,\n",
    "        color=\"teal\",\n",
    "    )\n",
    "    plt.yticks([0, 1], [\"Not-Music\", \"Music\"])\n",
    "    plt.xlabel(\"Time (Minutes)\")\n",
    "    plt.ylabel(\"Classification\")\n",
    "    plt.title(\"Music Detection Timeline\")\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_plot_path:\n",
    "        plt.savefig(save_plot_path, dpi=300, bbox_inches=\"tight\")\n",
    "        print(f\"Plot saved to: {save_plot_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def generate_music_timeline(file_path, window_sec, model, sr=22050):\n",
    "    total_duration = _get_duration(file_path)\n",
    "    total_chunks = int(total_duration // window_sec)\n",
    "\n",
    "    # Calculate bytes per chunk: (seconds * rate * 4 bytes for float32)\n",
    "    bytes_per_chunk = window_sec * sr * 4\n",
    "    results = []\n",
    "\n",
    "    # Use FFmpeg to pipe RAW PCM data to Python\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\",\n",
    "        file_path,\n",
    "        \"-f\",\n",
    "        \"f32le\",\n",
    "        \"-acodec\",\n",
    "        \"pcm_f32le\",\n",
    "        \"-ar\",\n",
    "        str(sr),\n",
    "        \"-ac\",\n",
    "        \"1\",\n",
    "        \"-\",\n",
    "    ]\n",
    "\n",
    "    process = subprocess.Popen(\n",
    "        command, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL\n",
    "    )\n",
    "\n",
    "    chunk_idx = 0\n",
    "    while True:\n",
    "        raw_bytes = process.stdout.read(bytes_per_chunk)\n",
    "        if not raw_bytes or len(raw_bytes) < bytes_per_chunk:\n",
    "            break\n",
    "\n",
    "        # Convert bytes to numpy\n",
    "        y_block = np.frombuffer(raw_bytes, dtype=np.float32)\n",
    "\n",
    "        # --- FEATURE EXTRACTION ---\n",
    "        mfccs = librosa.feature.mfcc(y=y_block, sr=sr, n_mfcc=13)\n",
    "        mfccs_mean = np.mean(mfccs.T, axis=0)\n",
    "        mfccs_std = np.std(mfccs.T, axis=0)\n",
    "        centroid = librosa.feature.spectral_centroid(y=y_block, sr=sr)\n",
    "        centroid_mean = np.mean(centroid)\n",
    "\n",
    "        features = np.hstack([mfccs_mean, mfccs_std, centroid_mean]).reshape(1, -1)\n",
    "\n",
    "        # --- PREDICTION ---\n",
    "        pred_idx = model.predict(features)[0]\n",
    "        prob = np.max(model.predict_proba(features))\n",
    "\n",
    "        start_time = chunk_idx * window_sec\n",
    "        results.append(\n",
    "            {\n",
    "                \"start_sec\": start_time,\n",
    "                \"end_sec\": start_time + window_sec,\n",
    "                \"label\": \"music\" if pred_idx == 1 else \"not-music\",\n",
    "                \"confidence\": round(prob, 4),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        chunk_idx += 1\n",
    "\n",
    "        # --- DISPLAY PERCENTAGE UPDATE ---\n",
    "        if (chunk_idx % 20 == 0) or (chunk_idx == total_chunks):\n",
    "            percent = int((chunk_idx / total_chunks) * 100)\n",
    "            # Limits display to 100% and prints on one line\n",
    "            print_status(\n",
    "                f\"Generating Music Timeline: {min(100, percent):>3}% complete\"\n",
    "            )\n",
    "\n",
    "    process.terminate()\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def _get_duration(file_path):\n",
    "    cmd = [\n",
    "        \"ffprobe\",\n",
    "        \"-v\",\n",
    "        \"error\",\n",
    "        \"-show_entries\",\n",
    "        \"format=duration\",\n",
    "        \"-of\",\n",
    "        \"default=noprint_wrappers=1:nokey=1\",\n",
    "        file_path,\n",
    "    ]\n",
    "    return float(subprocess.check_output(cmd))\n",
    "\n",
    "\n",
    "def extract_music_blocks(df, min_duration_sec=120, max_gap_seconds=15):\n",
    "    print_status(\"Extracting music blocks...\")\n",
    "    \n",
    "    # Create a copy so we don't overwrite the original dataframe\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # 1. Convert to numeric for processing\n",
    "    df_clean[\"is_music\"] = df_clean[\"label\"].map({\"music\": 1, \"not-music\": 0})\n",
    "\n",
    "    # 2. SMOOTHING: Median filter - requires at least 2/3 chunks to match.\n",
    "    df_clean[\"is_music\"] = (\n",
    "        df_clean[\"is_music\"]\n",
    "        .rolling(window=3, center=True)\n",
    "        .median()\n",
    "        .fillna(df_clean[\"is_music\"])\n",
    "    )\n",
    "\n",
    "    # 3. BRIDGE GAPS: check if music exists within the 'max_gap' range\n",
    "    # Treat \"not-music\" sections as \"music\" if shorter than max_gap_seconds,\n",
    "    gap_chunks = max_gap_seconds // CLIP_SIZE\n",
    "    df_clean[\"is_music\"] = (\n",
    "        df_clean[\"is_music\"]\n",
    "        .rolling(window=gap_chunks, center=True, min_periods=1)\n",
    "        .max()\n",
    "    )\n",
    "\n",
    "    # 4. Identify song blocks using cumsum logic\n",
    "    df_clean[\"block_id\"] = (\n",
    "        df_clean[\"is_music\"] != df_clean[\"is_music\"].shift()\n",
    "    ).cumsum()\n",
    "\n",
    "    # 5. Group and Aggregate\n",
    "    blocks = df_clean.groupby(\"block_id\").agg(\n",
    "        {\"is_music\": \"first\", \"start_sec\": \"min\", \"end_sec\": \"max\"}\n",
    "    )\n",
    "\n",
    "    blocks[\"duration\"] = blocks[\"end_sec\"] - blocks[\"start_sec\"]\n",
    "\n",
    "    # 6. Filter by music label (1) and min_duration threshold\n",
    "    songs = blocks[\n",
    "        (blocks[\"is_music\"] == 1) & (blocks[\"duration\"] >= min_duration_sec)\n",
    "    ].copy()\n",
    "\n",
    "    # Formatting helper\n",
    "    def format_time(seconds):\n",
    "        return f\"{int(seconds // 60):02d}:{int(seconds % 60):02d}\"\n",
    "\n",
    "    songs[\"start_timestamp\"] = songs[\"start_sec\"].apply(format_time)\n",
    "    songs[\"end_timestamp\"] = songs[\"end_sec\"].apply(format_time)\n",
    "\n",
    "    songs = songs.reset_index()  # moves block_id from index to column\n",
    "\n",
    "    return songs[\n",
    "        [\n",
    "            \"block_id\",\n",
    "            \"start_timestamp\",\n",
    "            \"end_timestamp\",\n",
    "            \"start_sec\",\n",
    "            \"end_sec\",\n",
    "            \"duration\",\n",
    "        ]\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b459cb98",
   "metadata": {},
   "source": [
    "Video Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4029cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_song_blocks(music_blocks, file_path, youtube_url, video=None, df_usages_lookup=None, debug=False):\n",
    "\n",
    "    print_status(\"Populating song blocks...\")\n",
    "\n",
    "    # Load video capture\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "\n",
    "    # Define video properties\n",
    "    # fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    lyric_start_row = int(height * 0.6)\n",
    "    lyric_end_row   = height\n",
    "\n",
    "    SHIFT_TIME = 30  # In case lyrics aren't showing at start and end of song\n",
    "\n",
    "    song_blocks = {}\n",
    "    for _, row in music_blocks.iterrows():\n",
    "        block_id = row['block_id']\n",
    "        block_start_time = row['start_sec']\n",
    "        block_end_time = row['end_sec']\n",
    "        \n",
    "        song_blocks[block_id] = []\n",
    "        \n",
    "        song_start_time = block_start_time\n",
    "        song_start_time_shifted = song_start_time + SHIFT_TIME\n",
    "        block_end_time_shifted = block_end_time - SHIFT_TIME\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"\\n--- Processing Music Block: {block_start_time}s to {block_end_time}s ---\")\n",
    "\n",
    "        # Get song_id at end (once)\n",
    "        song_id_end = None\n",
    "        while (song_id_end is None) and (block_end_time_shifted > block_start_time):\n",
    "            song_end = _get_best_matching_song(cap, lyric_start_row, lyric_end_row, width, block_end_time_shifted, video=video, df_usages_lookup=df_usages_lookup, debug=debug)\n",
    "            if not song_end:\n",
    "                block_end_time_shifted -= SHIFT_TIME # Shift back if nothing found\n",
    "                continue\n",
    "            song_id_end = song_end[\"id\"]\n",
    "        if song_id_end is None:\n",
    "            if debug:\n",
    "                print(\"NO SONG FOUND IN THIS SONG BLOCK\")\n",
    "            continue\n",
    "        \n",
    "        # ===== GET SONG(S) IN SONG BLOCK =====\n",
    "        while song_start_time_shifted < block_end_time_shifted:\n",
    "\n",
    "            # Get song_id at start of song\n",
    "            song_id_start = None\n",
    "            while (song_id_start is None) and (song_start_time_shifted < block_end_time_shifted):\n",
    "                song_start = _get_best_matching_song(cap, lyric_start_row, lyric_end_row, width, song_start_time_shifted, video=video, df_usages_lookup=df_usages_lookup, debug=debug)\n",
    "                if not song_start:\n",
    "                    song_start_time_shifted += SHIFT_TIME # Shift forward if nothing found\n",
    "                    continue\n",
    "                song_id_start = song_start[\"id\"]\n",
    "                song_first_line_start = song_start[\"first_line\"]\n",
    "            if song_id_start is None:\n",
    "                if debug:\n",
    "                    print(\"NO SONG FOUND IN THIS SONG BLOCK\")\n",
    "                break\n",
    "\n",
    "            # Check if song covers rest of song block\n",
    "            if song_id_start == song_id_end:\n",
    "                if debug:\n",
    "                    print(f\"SONG COMPLETED: {song_start}\")\n",
    "                \n",
    "                song_blocks[block_id].append({\n",
    "                    \"id\": song_id_start,\n",
    "                    \"first_line\": song_first_line_start,\n",
    "                    \"start\": song_start_time,\n",
    "                    \"end\": block_end_time,\n",
    "                    \"start_format\": _format_timestamp(song_start_time),\n",
    "                    \"end_format\": _format_timestamp(block_end_time),\n",
    "                    \"url\": youtube_url,\n",
    "                    })\n",
    "                break # Entire block is one song, we are done with this block\n",
    "\n",
    "            # ============= Multiple songs in song block =============\n",
    "            if debug:\n",
    "                print(f\"MULTIPLE SONGS IN BLOCK - commence binary search..\")\n",
    "\n",
    "            # Binary search for the transition point\n",
    "            end_time = _get_song_end_time(song_start_time_shifted, block_end_time_shifted, lyric_start_row, lyric_end_row, width, song_id_start, cap, video=video, df_usages_lookup=df_usages_lookup, debug=debug)\n",
    "\n",
    "            # Assume delay in changing lyrics to new song\n",
    "            end_time -= 5\n",
    "\n",
    "            if debug:\n",
    "                print(f\"SONG COMPLETED: {song_start}\")\n",
    "\n",
    "            song_blocks[block_id].append({\n",
    "                \"id\": song_id_start,\n",
    "                \"first_line\": song_first_line_start,\n",
    "                \"start\": song_start_time,\n",
    "                \"end\": end_time,\n",
    "                \"start_format\": _format_timestamp(song_start_time),\n",
    "                \"end_format\": _format_timestamp(end_time),\n",
    "                \"url\": youtube_url,\n",
    "                })\n",
    "            \n",
    "            song_start_time = end_time  # Move to the start of the next song\n",
    "            song_start_time_shifted = song_start_time + SHIFT_TIME\n",
    "\n",
    "    cap.release()\n",
    "    return song_blocks\n",
    "\n",
    "\n",
    "def _format_timestamp(seconds: int) -> str:\n",
    "    h, r = divmod(int(seconds), 3600)\n",
    "    m, s = divmod(r, 60)\n",
    "    return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
    "\n",
    "\n",
    "def _identify_songs_from_lyrics(search_text, df_lyrics, threshold=80):\n",
    "    search_text_cleaned = clean_text(search_text)\n",
    "    \n",
    "    if not search_text_cleaned or len(search_text_cleaned) < 10:\n",
    "        return []\n",
    "\n",
    "    # extract returns a list of (string, score, index) tuples\n",
    "    results = process.extract(\n",
    "        search_text_cleaned, \n",
    "        df_lyrics['cleaned'], \n",
    "        scorer=fuzz.partial_ratio,\n",
    "        # scorer=fuzz.token_set_ratio,  # could try this instead\n",
    "        score_cutoff=threshold,\n",
    "        limit=5 \n",
    "    )\n",
    "\n",
    "    matches = []\n",
    "    for _, score, idx in results:\n",
    "        match_row = df_lyrics.iloc[idx]\n",
    "        matches.append({\n",
    "            \"id\": int(match_row[\"song_id\"]),\n",
    "            \"first_line\": match_row[\"first_line\"],\n",
    "            \"score\": round(float(score), 1)\n",
    "        })\n",
    "\n",
    "    # RapidFuzz's extract automatically sorts by score DESC\n",
    "    return matches\n",
    "\n",
    "\n",
    "def _display_images(lyric_zone, thresh):\n",
    "    \"\"\"View original image frame and formatted frame seen by OCR\"\"\"\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    ax[0].imshow(cv2.cvtColor(lyric_zone, cv2.COLOR_BGR2RGB))\n",
    "    ax[0].set_title(\"Original Crop\")\n",
    "\n",
    "    ax[1].imshow(thresh, cmap='gray')\n",
    "    ax[1].set_title(\"Thresholded (OCR Input)\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def _get_screen_text(frame, lyric_start_row, lyric_end_row, width, debug):\n",
    "    \"\"\"Return text shown on specified region of screen\"\"\"\n",
    "    \n",
    "    # 1. CROP: Keep only the bottom section\n",
    "    lyric_zone = frame[lyric_start_row:lyric_end_row, 0:width]\n",
    "\n",
    "    # 2. GRAYSCALE: Process only the small cropped area\n",
    "    gray_lyric = cv2.cvtColor(lyric_zone, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 3. THRESHOLD: High Contrast (Makes OCR 2x more accurate)\n",
    "    _, thresh = cv2.threshold(gray_lyric, 200, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # 4. OCR: read lyrics\n",
    "    results = reader.readtext(thresh, detail=0)\n",
    "    if not results:\n",
    "        if debug:\n",
    "            _display_images(lyric_zone, thresh)\n",
    "        return None\n",
    "\n",
    "    # 5. FORMAT: convert from list to string\n",
    "    text = \" \".join(results)    \n",
    "    if len(text) < 20:  # catch random noise or too few lyrics\n",
    "        return None\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def _get_song_end_time(left, right, lyric_start_row, lyric_end_row, width, song_id, cap, debug, video=None, df_usages_lookup=None):\n",
    "    \"\"\"Binary search for time when changes from one song to another\"\"\"\n",
    "\n",
    "    while (right - left) > 2:  # Stop when within 2 seconds\n",
    "        mid = (left + right) // 2\n",
    "        \n",
    "        song = _get_best_matching_song(cap, lyric_start_row, lyric_end_row, width, mid, video=video, df_usages_lookup=df_usages_lookup, debug=debug)\n",
    "        if not song:\n",
    "            # Catch no song match (e.g. lyrics not displayed on screen)\n",
    "            right = right - 10\n",
    "            continue\n",
    "        \n",
    "        mid_id = song[\"id\"]\n",
    "\n",
    "        if mid_id == song_id:\n",
    "            left = mid\n",
    "        else:\n",
    "            right = mid\n",
    "\n",
    "    return left\n",
    "\n",
    "\n",
    "def _get_best_matching_song(cap, lyric_start_row, lyric_end_row, width, sec, debug, video=None, df_usages_lookup=None):\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, sec * 1000)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        return None\n",
    "\n",
    "    text = _get_screen_text(frame, lyric_start_row, lyric_end_row, width, debug=debug)\n",
    "    songs = _identify_songs_from_lyrics(text, df_lyrics)\n",
    "    \n",
    "    if not songs:\n",
    "        if debug:\n",
    "            print(f\"{sec}s: NO MATCH FOUND: text={text}\")\n",
    "        return None\n",
    "    \n",
    "    if len(songs) == 1 or video is None:\n",
    "        # If video is None, can't search usage data anyway since don't have video date\n",
    "        return songs[0]\n",
    "\n",
    "    # Search usage data \n",
    "    if True:\n",
    "        song_candidates = [s[\"first_line\"] for s in songs]\n",
    "        print(f\"Song candidates: {', '.join(song_candidates)}\")\n",
    "    target_date = video[\"date\"]\n",
    "    church_activity_id = video[\"church_activity_id\"]\n",
    "    for song in songs:\n",
    "        # Loop until match is found\n",
    "        for date_candidate in _get_dates_to_try(target_date):\n",
    "            try:\n",
    "                match = df_usages_lookup.loc[(song[\"id\"], date_candidate, church_activity_id)]\n",
    "                if not match.empty:\n",
    "                    return song\n",
    "            except KeyError:\n",
    "                continue\n",
    "    \n",
    "    # Fallback\n",
    "    return songs[0]\n",
    "\n",
    "\n",
    "def display_song_block_summary(song_blocks):\n",
    "    for block_id in song_blocks.keys():\n",
    "        print(\"---\".ljust(80))\n",
    "        for song in song_blocks[block_id]:\n",
    "            print(f'{song[\"start_format\"]} - {song[\"url\"]}&t={song[\"start\"]} - {song[\"first_line\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a53018",
   "metadata": {},
   "source": [
    "SongYouTubeLink Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bad04f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "\n",
    "def add_song_youtube_link(\n",
    "    df_usages_lookup,\n",
    "    video,\n",
    "    song,\n",
    "    debug=False,\n",
    "):\n",
    "\n",
    "    target_date = video[\"date\"]\n",
    "    church_activity_id = video[\"church_activity_id\"]\n",
    "\n",
    "    match = None\n",
    "    final_used_date = None\n",
    "\n",
    "    # Loop until match is found\n",
    "    for date_candidate in _get_dates_to_try(target_date):\n",
    "        try:\n",
    "            match = df_usages_lookup.loc[(song[\"id\"], date_candidate, church_activity_id)]\n",
    "            final_used_date = date_candidate\n",
    "            break # Exit loop if found\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "    # Handle case when usage not found\n",
    "    if match is None:\n",
    "        print_link_update_status_msg(\"❗ No usage found\", song, final_used_date, None, None)\n",
    "        return False\n",
    "\n",
    "    # Extract Usage ID\n",
    "    usage_id = int(match[\"id\"].iloc[0] if hasattr(match, \"iloc\") else match[\"id\"])\n",
    "\n",
    "    # Perform Duplicate Check\n",
    "    existing_id = _get_existing_link_id_at_time(match, song[\"start\"])\n",
    "    if existing_id:\n",
    "        if debug:\n",
    "            print_link_update_status_msg(\"ℹ️ SKIP - Timestamp match\", song, final_used_date, usage_id, existing_id)\n",
    "        return existing_id\n",
    "\n",
    "    # Build video title\n",
    "    title = _build_video_title(link_title_PREFIX, final_used_date, song[\"first_line\"])\n",
    "\n",
    "    # Define query\n",
    "    insert_query = text(\n",
    "        \"\"\"\n",
    "        INSERT INTO song_youtube_links \n",
    "        (song_usage_id, url, start_seconds, end_seconds, title, is_featured)\n",
    "        VALUES (:song_usage_id, :url, :start_seconds, :end_seconds, :title, False)\n",
    "        RETURNING id\n",
    "        \"\"\"\n",
    "    )\n",
    "    params = {\n",
    "        \"song_usage_id\": usage_id,\n",
    "        \"url\": song[\"url\"],\n",
    "        \"start_seconds\": song[\"start\"],\n",
    "        \"end_seconds\": song[\"end\"],\n",
    "        \"title\": title,\n",
    "    }\n",
    "\n",
    "    # Add entry to SongYouTubeLink\n",
    "    new_link_id = None\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            result = conn.execute(insert_query, params)\n",
    "            new_link_id = result.scalar() \n",
    "    except SQLAlchemyError as e:\n",
    "        print_link_update_status_msg(f\"❗ Database error: {e}\", song, final_used_date, None, None)\n",
    "        return None\n",
    "    \n",
    "    # === UPDATE df_usages_lookup ===\n",
    "    # 1. Target the specific index\n",
    "    idx = (song[\"id\"], final_used_date, church_activity_id)\n",
    "\n",
    "    # 2. Get the current list (handling potential multiple rows)\n",
    "    matches = df_usages_lookup.loc[idx, \"existing_links\"]\n",
    "    current_val = matches.iloc[0] if hasattr(matches, \"iloc\") else matches\n",
    "\n",
    "    # 3. Ensure it's a list and append\n",
    "    if not isinstance(current_val, list):\n",
    "        current_val = []\n",
    "    current_val.append({\"id\": new_link_id, \"t\": song[\"start\"]})\n",
    "\n",
    "    # 4. WRITE BACK using .loc (this safely updates all duplicate rows at once)\n",
    "    # Note: We wrap in a Series or just use .loc directly to avoid 'Must be same length' errors\n",
    "    df_usages_lookup.loc[idx, \"existing_links\"] = [current_val] * (len(matches) if hasattr(matches, \"__len__\") else 1)\n",
    "\n",
    "    # Log success\n",
    "    if debug:\n",
    "        print_link_update_status_msg(f\"✅ Added link\", song, final_used_date, usage_id, new_link_id)\n",
    "\n",
    "    return new_link_id\n",
    "\n",
    "\n",
    "def _build_video_title(link_title_PREFIX, final_used_date, song_first_line):\n",
    "    return f\"{link_title_PREFIX} {final_used_date.strftime(\"%d/%m/%y\")} - {song_first_line}\"\n",
    "\n",
    "\n",
    "def _get_existing_link_id_at_time(match, current_start, buffer=15):\n",
    "    # Get the list of dictionaries\n",
    "    links = match[\"existing_links\"].iloc[0] if hasattr(match, \"iloc\") else match[\"existing_links\"]\n",
    "    \n",
    "    if not links:\n",
    "        return None\n",
    "        \n",
    "    for link in links:\n",
    "        # Check if the current timestamp is within the buffer of an existing record\n",
    "        if abs(link[\"t\"] - current_start) <= buffer:\n",
    "            return link[\"id\"] # Return the specific link_id\n",
    "            \n",
    "    return None\n",
    "\n",
    "\n",
    "def print_link_update_status_msg(headline, song, used_date, usage_id, link_id):\n",
    "    print(f'{headline} - {song[\"url\"]}&t={song[\"start\"]}')\n",
    "    print(f' - {used_date} - usage_id {usage_id} - link_id {link_id} - song_id {song[\"id\"]} - {song[\"first_line\"]}')\n",
    "\n",
    "\n",
    "def usage_link_may_already_exist(df_usages_lookup, target_date, church_activity_id):\n",
    "    \"\"\"\n",
    "    Used for quick search to avoid costly song identification.\n",
    "    \n",
    "    Since it doesn't check for specific songs, this won't catch situations\n",
    "    where some song usage links have been added but others have not.\n",
    "    \"\"\"\n",
    "    for date_candidate in _get_dates_to_try(target_date):\n",
    "        try:\n",
    "            # with .xs can skip 'song_id' and filter by the other levels\n",
    "            match = df_usages_lookup.xs((date_candidate, church_activity_id), \n",
    "                                        level=('used_date', 'church_activity_id'))\n",
    "            if (match[\"link_count\"] > 0).any():\n",
    "                return True\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5d200c",
   "metadata": {},
   "source": [
    "SongYouTubeLink Manual Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3532b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_usage_id(song_id, used_at_activity_id, used_date):\n",
    "    # Convert string to date object\n",
    "    target_date_obj = date.fromisoformat(used_date)\n",
    "\n",
    "    # Find song usages which match criteria\n",
    "    match = df_usages[\n",
    "        (df_usages[\"church_activity_id\"] == used_at_activity_id) &\n",
    "        (df_usages[\"song_id\"] == song_id) &\n",
    "        (df_usages[\"used_date\"] == target_date_obj)\n",
    "    ]\n",
    "    if match.empty:\n",
    "        print(\"❗ No song usages match criteria\")\n",
    "        return None\n",
    "    \n",
    "    if len(match) > 1:\n",
    "        print(\"❗ Multiple song usages match criteria! Please specify song_usage_id manually\")\n",
    "        display(match)\n",
    "        return None\n",
    "    \n",
    "    song_usage_id = int(match[\"id\"].iloc[0])\n",
    "    print(f\"✅ song_usage_id set to {song_usage_id}\")\n",
    "    \n",
    "    return song_usage_id\n",
    "\n",
    "\n",
    "def convert_time_str_to_seconds(time_str):\n",
    "    return sum(int(x) * 60**i for i, x in enumerate(reversed(time_str.split(\":\"))))\n",
    "\n",
    "\n",
    "def add_song_link_manually(\n",
    "    song_usage_id,\n",
    "    url,\n",
    "    start_seconds,\n",
    "    end_seconds,\n",
    "    title,\n",
    "    is_featured=False,\n",
    "    description=None,\n",
    "    thumbnail_key=None,\n",
    "):\n",
    "    insert_query = text(\n",
    "        \"\"\"\n",
    "        INSERT INTO song_youtube_links \n",
    "        (song_usage_id, url, start_seconds, end_seconds, title, is_featured, description, thumbnail_key)\n",
    "        VALUES (:song_usage_id, :url, :start_seconds, :end_seconds, :title, :is_featured, :description, :thumbnail_key)\n",
    "        RETURNING id\n",
    "        \"\"\"\n",
    "    )\n",
    "    params = {\n",
    "        \"song_usage_id\": song_usage_id,\n",
    "        \"url\": url,\n",
    "        \"start_seconds\": start_seconds,\n",
    "        \"end_seconds\": end_seconds,\n",
    "        \"title\": title,\n",
    "        \"is_featured\": is_featured,\n",
    "        \"description\": description,\n",
    "        \"thumbnail_key\": thumbnail_key,\n",
    "    }\n",
    "\n",
    "    # Add entry to SongYouTubeLink\n",
    "    new_link_id = None\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            result = conn.execute(insert_query, params)\n",
    "            new_link_id = result.scalar()\n",
    "            print(f\"✅ Added link {new_link_id}\")\n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"❗ Database error: {e}\")\n",
    "    \n",
    "    return new_link_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2259d207",
   "metadata": {},
   "source": [
    "## MANUAL_MODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded5eb39",
   "metadata": {},
   "source": [
    "This section allows for manually adding song links if automated procedure doesn't work.\n",
    "\n",
    "Use with care as duplicate checks are disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a6cdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MANUAL_MODE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f5349d",
   "metadata": {},
   "source": [
    "View activity_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dadae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MANUAL_MODE:\n",
    "    display(df_activities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3f9f11",
   "metadata": {},
   "source": [
    "View song_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad94aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_lyrics_contain = \"this earth belongs\"\n",
    "\n",
    "if MANUAL_MODE:\n",
    "    results = df_lyrics[df_lyrics[\"content\"].str.contains(song_lyrics_contain, case=False, na=False)]\n",
    "    display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215f2fe8",
   "metadata": {},
   "source": [
    "View church_activity_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588fdf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MANUAL_MODE:\n",
    "    display(df_activities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f931d951",
   "metadata": {},
   "source": [
    "View song usages near date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5bc745",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MANUAL_MODE:\n",
    "\n",
    "    # --- Required parameters\n",
    "    url = \"https://www.youtube.com/watch?v=Pduvp1q4u4M\"\n",
    "    start_seconds = convert_time_str_to_seconds(\"18:37\")\n",
    "    end_seconds = convert_time_str_to_seconds(\"21:09\")\n",
    "    title = \"Newland AM 02/04/2023 - This Earth Belongs To God\"\n",
    "\n",
    "    song_id = 1442\n",
    "    used_at_activity_id = 1\n",
    "    used_date = \"2023-04-02\"\n",
    "    song_usage_id = get_song_usage_id(song_id, used_at_activity_id, used_date)\n",
    "\n",
    "    if song_usage_id is None:\n",
    "        raise Exception(\"song_usage_id not found\")\n",
    "\n",
    "    # --- Optional parameters\n",
    "    is_featured = False\n",
    "    description = None\n",
    "    thumbnail_key = None\n",
    "\n",
    "    # ============================== Add Song Link ==============================\n",
    "    new_link_id = add_song_link_manually(\n",
    "        song_usage_id=song_usage_id,\n",
    "        url=url,\n",
    "        start_seconds=start_seconds,\n",
    "        end_seconds=end_seconds,\n",
    "        title=title,\n",
    "        is_featured=False,\n",
    "        description=None,\n",
    "        thumbnail_key=None,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ac3816",
   "metadata": {},
   "source": [
    "## Run Main Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e78ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_videos = len(youtube_videos)\n",
    "\n",
    "for i, video in enumerate(youtube_videos, 1):\n",
    "    \n",
    "    print(f\"\\n##### Video {i} of {total_videos} - {video[\"title\"]} ###\")\n",
    "\n",
    "    some_links_found = usage_link_may_already_exist(\n",
    "        df_usages_lookup, video[\"date\"], video[\"church_activity_id\"])\n",
    "    \n",
    "    if some_links_found and SKIP_IF_LINKS_MAY_EXIST:\n",
    "        print(f'ℹ️ Existing links found for church_activity_id {video[\"church_activity_id\"]} near this date. Skipping.')\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # ===== AUDIO =====\n",
    "        tmp_audio = download_audio(output_path=OUTPUT_AUDIO, youtube_url=video[\"url\"])\n",
    "        df_blocks = generate_music_timeline(file_path=tmp_audio, window_sec=CLIP_SIZE, model=model)\n",
    "        # plot_music_blocks(df=df_blocks)\n",
    "        music_blocks = extract_music_blocks(df_blocks, min_duration_sec=120, max_gap_seconds=15)\n",
    "\n",
    "        # ===== VIDEO =====\n",
    "        tmp_video = download_video(output_path=OUTPUT_VIDEO, youtube_url=video[\"url\"])\n",
    "        song_blocks = populate_song_blocks(file_path=tmp_video, music_blocks=music_blocks, youtube_url=video[\"url\"], video=video, df_usages_lookup=df_usages_lookup)\n",
    "        # display_song_block_summary(song_blocks)\n",
    "        \n",
    "        # Add Song YouTube Links to Database\n",
    "        for block_id, songs in song_blocks.items():\n",
    "            for song in songs:\n",
    "                add_song_youtube_link(\n",
    "                    df_usages_lookup,\n",
    "                    video,\n",
    "                    song,\n",
    "                    debug=True,\n",
    "                )\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ Skipping {video['title']} - YouTube Download Failed - {e}\")\n",
    "        continue\n",
    "    \n",
    "    except Exception as e:\n",
    "        # This is the \"Safety Net\" for anything else\n",
    "        print(f\"❗ Unexpected error processing {video['title']}: {type(e).__name__} - {e}\")\n",
    "        continue "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
