{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6956c56f",
   "metadata": {},
   "source": [
    "# Predict Song Blocks Using Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf3d139",
   "metadata": {},
   "source": [
    "This notebook predicts song blocks using the trained model. It downloads the audio from a specified YouTube video and makes the analysis on this audio file.\n",
    "\n",
    "Inputs:\n",
    "- YouTube video URL\n",
    "- Model (trained in notebook 02)\n",
    "\n",
    "Outputs:\n",
    "- Music Timeline Plot (PNG)\n",
    "- Music Block summary (CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d281c41",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de27cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def734e1",
   "metadata": {},
   "source": [
    "## SETTINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc376cb4",
   "metadata": {},
   "source": [
    "Model directory and filename (copied from notebook 02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab350f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = Path(\"..\") / \"models\"  # '..' moves up one level to project root\n",
    "MODEL_FILENAME = \"music_classifier.pkl\"\n",
    "\n",
    "# === Create the folders if they don't exist ===\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba628de0",
   "metadata": {},
   "source": [
    "Data Directories (copied from notebook 01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192a93be",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"..\") / \"data\"  # '..' moves up one level to project root\n",
    "\n",
    "RAW_DATA_DIR = DATA_DIR / \"raw\"\n",
    "CLIPS_DATA_DIR = DATA_DIR / \"clips\"\n",
    "\n",
    "STAGING_DIR = CLIPS_DATA_DIR / \"segments\"\n",
    "\n",
    "MUSIC_CLIPS_DIR = CLIPS_DATA_DIR / \"music\"\n",
    "NOT_MUSIC_CLIPS_DIR = CLIPS_DATA_DIR / \"not-music\"\n",
    "\n",
    "# === Create the folders if they don't exist ===\n",
    "RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "STAGING_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MUSIC_CLIPS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "NOT_MUSIC_CLIPS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea26d0",
   "metadata": {},
   "source": [
    "Data Results Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c4f9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = DATA_DIR / \"results\"\n",
    "\n",
    "# === Create the folders if they don't exist ===\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb347f8",
   "metadata": {},
   "source": [
    "Output Audio filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e7fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_AUDIO = RAW_DATA_DIR / \"output_audio.m4a\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795ee1d8",
   "metadata": {},
   "source": [
    "YouTube video URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8885364",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.youtube.com/watch?v=GA6knmK1UKs\"  # Original YouTube Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a5932d",
   "metadata": {},
   "source": [
    "Clip size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fbd5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_SIZE = 5  # Size of analysis window (seconds) - use same value as in notebook 01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808bf1b8",
   "metadata": {},
   "source": [
    "## Download Audio for YouTube Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd91baa",
   "metadata": {},
   "source": [
    "Download audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e397c9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yt-dlp -q --force-overwrites -f \"bestaudio[ext=m4a]/bestaudio\" -o \"{OUTPUT_AUDIO}\" {URL}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ac3816",
   "metadata": {},
   "source": [
    "## Make Predictions Using Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9609710",
   "metadata": {},
   "source": [
    "Generate dataframe of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca87d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(MODELS_DIR / MODEL_FILENAME)\n",
    "\n",
    "\n",
    "def get_duration(file_path):\n",
    "    cmd = [\n",
    "        'ffprobe', '-v', 'error', '-show_entries', 'format=duration',\n",
    "        '-of', 'default=noprint_wrappers=1:nokey=1', file_path\n",
    "    ]\n",
    "    return float(subprocess.check_output(cmd))\n",
    "\n",
    "\n",
    "def predict_music_timeline(file_path, window_sec, sr=22050):\n",
    "    total_duration = get_duration(file_path)\n",
    "    total_chunks = int(total_duration // window_sec)\n",
    "    \n",
    "    # Calculate bytes per chunk: (seconds * rate * 4 bytes for float32)\n",
    "    bytes_per_chunk = window_sec * sr * 4\n",
    "    results = []\n",
    "    \n",
    "    # Use FFmpeg to pipe RAW PCM data to Python\n",
    "    command = [\n",
    "        'ffmpeg', '-i', file_path,\n",
    "        '-f', 'f32le', '-acodec', 'pcm_f32le',\n",
    "        '-ar', str(sr), '-ac', '1', '-'\n",
    "    ]\n",
    "    \n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL)\n",
    "    \n",
    "    chunk_idx = 0\n",
    "    while True:\n",
    "        raw_bytes = process.stdout.read(bytes_per_chunk)\n",
    "        if not raw_bytes or len(raw_bytes) < bytes_per_chunk:\n",
    "            break\n",
    "            \n",
    "        # Convert bytes to numpy\n",
    "        y_block = np.frombuffer(raw_bytes, dtype=np.float32)\n",
    "        \n",
    "        # --- FEATURE EXTRACTION ---\n",
    "        mfccs = librosa.feature.mfcc(y=y_block, sr=sr, n_mfcc=13)\n",
    "        mfccs_mean = np.mean(mfccs.T, axis=0)\n",
    "        mfccs_std = np.std(mfccs.T, axis=0)\n",
    "        centroid = librosa.feature.spectral_centroid(y=y_block, sr=sr)\n",
    "        centroid_mean = np.mean(centroid)\n",
    "        \n",
    "        features = np.hstack([mfccs_mean, mfccs_std, centroid_mean]).reshape(1, -1)\n",
    "        \n",
    "        # --- PREDICTION ---\n",
    "        pred_idx = model.predict(features)[0]\n",
    "        prob = np.max(model.predict_proba(features))\n",
    "        \n",
    "        start_time = chunk_idx * window_sec\n",
    "        results.append({\n",
    "            \"start_sec\": start_time,\n",
    "            \"end_sec\": start_time + window_sec,\n",
    "            \"label\": \"music\" if pred_idx == 1 else \"not-music\",\n",
    "            \"confidence\": round(prob, 4)\n",
    "        })\n",
    "        \n",
    "        chunk_idx += 1\n",
    "        \n",
    "        # --- DISPLAY PERCENTAGE UPDATE ---\n",
    "        if chunk_idx % 20 == 0:\n",
    "            percent = int((chunk_idx / total_chunks) * 100)\n",
    "            # Limits display to 100% and prints on one line\n",
    "            print(f\"Progress: {min(100, percent):>3}% complete\", end=\"\\r\")\n",
    "\n",
    "    process.terminate()\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Get music predictions timeline\n",
    "file_path = OUTPUT_AUDIO\n",
    "df = predict_music_timeline(file_path=file_path, window_sec=CLIP_SIZE)\n",
    "\n",
    "print(\"\\nHere are first few rows..\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d7d4c3",
   "metadata": {},
   "source": [
    "Show predictions on a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58d35a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Prepare data for plotting\n",
    "# Convert labels to numbers (1 for music, 0 for not-music)\n",
    "df['label_num'] = df['label'].map({'music': 1, 'not-music': 0})\n",
    "\n",
    "# 2. Setup the plot\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.step(df['start_sec'] / 60, df['label_num'], where='post', color='teal', linewidth=2)\n",
    "\n",
    "# 3. Formatting\n",
    "plt.fill_between(df['start_sec'] / 60, df['label_num'], step=\"post\", alpha=0.3, color='teal')\n",
    "plt.yticks([0, 1], ['Not-Music', 'Music'])\n",
    "plt.xlabel('Time (Minutes)')\n",
    "plt.ylabel('Classification')\n",
    "plt.title('Music Detection Timeline')\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plot_path = RESULTS_DIR / \"music_timeline_plot.png\"\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "print(f\"Plot successfully saved to: {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be57224f",
   "metadata": {},
   "source": [
    "Extract song blocks from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc59e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_music_blocks(df, min_duration_sec=120, max_gap_seconds=15):\n",
    "    # Create a copy so we don't overwrite the original dataframe\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # 1. Convert to numeric for processing\n",
    "    df_clean['is_music'] = df_clean['label'].map({'music': 1, 'not-music': 0})\n",
    "    \n",
    "    # 2. SMOOTHING: Median filter - requires at least 2/3 chunks to match.\n",
    "    df_clean['is_music'] = df_clean['is_music'].rolling(window=3, center=True).median().fillna(df_clean['is_music'])\n",
    "    \n",
    "    # 3. BRIDGE GAPS: check if music exists within the 'max_gap' range\n",
    "    # Treat \"not-music\" sections as \"music\" if shorter than max_gap_seconds, \n",
    "    gap_chunks = max_gap_seconds // CLIP_SIZE\n",
    "    df_clean['is_music'] = df_clean['is_music'].rolling(window=gap_chunks, center=True, min_periods=1).max()\n",
    "\n",
    "    # 4. Identify song blocks using cumsum logic\n",
    "    df_clean['block_id'] = (df_clean['is_music'] != df_clean['is_music'].shift()).cumsum()\n",
    "\n",
    "    # 5. Group and Aggregate\n",
    "    blocks = df_clean.groupby('block_id').agg({\n",
    "        'is_music': 'first',\n",
    "        'start_sec': 'min',\n",
    "        'end_sec': 'max'\n",
    "    })\n",
    "    \n",
    "    blocks['duration'] = blocks['end_sec'] - blocks['start_sec']\n",
    "\n",
    "    # 6. Filter by music label (1) and min_duration threshold\n",
    "    songs = blocks[(blocks['is_music'] == 1) & (blocks['duration'] >= min_duration_sec)].copy()\n",
    "\n",
    "    # Formatting helper\n",
    "    def format_time(seconds):\n",
    "        return f\"{int(seconds // 60):02d}:{int(seconds % 60):02d}\"\n",
    "\n",
    "    songs['start_timestamp'] = songs['start_sec'].apply(format_time)\n",
    "    songs['end_timestamp'] = songs['end_sec'].apply(format_time)\n",
    "\n",
    "    return songs[['start_timestamp', 'end_timestamp', 'start_sec', 'end_sec', 'duration']]\n",
    "\n",
    "# Get music blocks\n",
    "music_blocks = extract_music_blocks(df, min_duration_sec=120, max_gap_seconds=15)\n",
    "music_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a2b076",
   "metadata": {},
   "source": [
    "Save song_blocks to results directory as csv (overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a39d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_blocks.to_csv(RESULTS_DIR / \"music_timeline.csv\", index=True)\n",
    "print(f\"Summary saved to {RESULTS_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
