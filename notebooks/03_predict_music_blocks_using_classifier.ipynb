{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6956c56f",
   "metadata": {},
   "source": [
    "# Predict Song Blocks Using Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf3d139",
   "metadata": {},
   "source": [
    "This notebook predicts song blocks using the trained model. It downloads the audio from a specified YouTube video and makes the analysis on this audio file.\n",
    "\n",
    "Inputs:\n",
    "- YouTube video URL\n",
    "- Model (trained in notebook 02)\n",
    "\n",
    "Outputs:\n",
    "- Music Timeline Plot (PNG)\n",
    "- Music Block summary (CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d281c41",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de27cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def734e1",
   "metadata": {},
   "source": [
    "## SETTINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6946a675",
   "metadata": {},
   "source": [
    "Add parent folder to python path (needed for retrieving YOUTUBE_URL from settings.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f199ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(str(Path(\"..\").resolve()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc376cb4",
   "metadata": {},
   "source": [
    "Model directory and filename (copied from notebook 02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab350f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = Path(\"..\") / \"models\"  # '..' moves up one level to project root\n",
    "MODEL_FILENAME = \"music_classifier.pkl\"\n",
    "\n",
    "# === Create the folders if they don't exist ===\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba628de0",
   "metadata": {},
   "source": [
    "Data Directories (copied from notebook 01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192a93be",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"..\") / \"data\"  # '..' moves up one level to project root\n",
    "\n",
    "RAW_DATA_DIR = DATA_DIR / \"raw\"\n",
    "CLIPS_DATA_DIR = DATA_DIR / \"clips\"\n",
    "RESULTS_DIR = DATA_DIR / \"results\"\n",
    "\n",
    "STAGING_DIR = CLIPS_DATA_DIR / \"segments\"\n",
    "MUSIC_CLIPS_DIR = CLIPS_DATA_DIR / \"music\"\n",
    "NOT_MUSIC_CLIPS_DIR = CLIPS_DATA_DIR / \"not-music\"\n",
    "\n",
    "# === Create the folders if they don't exist ===\n",
    "RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "STAGING_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MUSIC_CLIPS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "NOT_MUSIC_CLIPS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb347f8",
   "metadata": {},
   "source": [
    "Output Audio filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e7fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_AUDIO = RAW_DATA_DIR / \"output_audio.m4a\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795ee1d8",
   "metadata": {},
   "source": [
    "YouTube video URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8885364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings import YOUTUBE_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a5932d",
   "metadata": {},
   "source": [
    "Clip size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fbd5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_SIZE = 5  # Size of analysis window (seconds) - use same value as in notebook 01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808bf1b8",
   "metadata": {},
   "source": [
    "## Download Audio for YouTube Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd91baa",
   "metadata": {},
   "source": [
    "Download audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e397c9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yt-dlp -q --force-overwrites -f \"bestaudio[ext=m4a]/bestaudio\" -o \"{OUTPUT_AUDIO}\" {YOUTUBE_URL}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69814dfe",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314eb396",
   "metadata": {},
   "source": [
    "Print status helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d488f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status(message, width=80):\n",
    "    print(message.ljust(width), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e05e52",
   "metadata": {},
   "source": [
    "Helpers relating to audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf25972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_music_blocks(df, save_plot_path=None):\n",
    "\n",
    "    df_plot = df.copy()\n",
    "\n",
    "    # 1. Prepare data for plotting\n",
    "    # Convert labels to numbers (1 for music, 0 for not-music)\n",
    "    df_plot[\"label_num\"] = df_plot[\"label\"].map({\"music\": 1, \"not-music\": 0})\n",
    "\n",
    "    # 2. Setup the plot\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.step(\n",
    "        df_plot[\"start_sec\"] / 60,\n",
    "        df_plot[\"label_num\"],\n",
    "        where=\"post\",\n",
    "        color=\"teal\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "\n",
    "    # 3. Formatting\n",
    "    plt.fill_between(\n",
    "        df_plot[\"start_sec\"] / 60,\n",
    "        df_plot[\"label_num\"],\n",
    "        step=\"post\",\n",
    "        alpha=0.3,\n",
    "        color=\"teal\",\n",
    "    )\n",
    "    plt.yticks([0, 1], [\"Not-Music\", \"Music\"])\n",
    "    plt.xlabel(\"Time (Minutes)\")\n",
    "    plt.ylabel(\"Classification\")\n",
    "    plt.title(\"Music Detection Timeline\")\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_plot_path:\n",
    "        plt.savefig(save_plot_path, dpi=300, bbox_inches=\"tight\")\n",
    "        print(f\"Plot saved to: {save_plot_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def generate_music_timeline(file_path, window_sec, model, sr=22050):\n",
    "    total_duration = _get_duration(file_path)\n",
    "    total_chunks = int(total_duration // window_sec)\n",
    "\n",
    "    # Calculate bytes per chunk: (seconds * rate * 4 bytes for float32)\n",
    "    bytes_per_chunk = window_sec * sr * 4\n",
    "    results = []\n",
    "\n",
    "    # Use FFmpeg to pipe RAW PCM data to Python\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\",\n",
    "        file_path,\n",
    "        \"-f\",\n",
    "        \"f32le\",\n",
    "        \"-acodec\",\n",
    "        \"pcm_f32le\",\n",
    "        \"-ar\",\n",
    "        str(sr),\n",
    "        \"-ac\",\n",
    "        \"1\",\n",
    "        \"-\",\n",
    "    ]\n",
    "\n",
    "    process = subprocess.Popen(\n",
    "        command, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL\n",
    "    )\n",
    "\n",
    "    chunk_idx = 0\n",
    "    while True:\n",
    "        raw_bytes = process.stdout.read(bytes_per_chunk)\n",
    "        if not raw_bytes or len(raw_bytes) < bytes_per_chunk:\n",
    "            break\n",
    "\n",
    "        # Convert bytes to numpy\n",
    "        y_block = np.frombuffer(raw_bytes, dtype=np.float32)\n",
    "\n",
    "        # --- FEATURE EXTRACTION ---\n",
    "        mfccs = librosa.feature.mfcc(y=y_block, sr=sr, n_mfcc=13)\n",
    "        mfccs_mean = np.mean(mfccs.T, axis=0)\n",
    "        mfccs_std = np.std(mfccs.T, axis=0)\n",
    "        centroid = librosa.feature.spectral_centroid(y=y_block, sr=sr)\n",
    "        centroid_mean = np.mean(centroid)\n",
    "\n",
    "        features = np.hstack([mfccs_mean, mfccs_std, centroid_mean]).reshape(1, -1)\n",
    "\n",
    "        # --- PREDICTION ---\n",
    "        pred_idx = model.predict(features)[0]\n",
    "        prob = np.max(model.predict_proba(features))\n",
    "\n",
    "        start_time = chunk_idx * window_sec\n",
    "        results.append(\n",
    "            {\n",
    "                \"start_sec\": start_time,\n",
    "                \"end_sec\": start_time + window_sec,\n",
    "                \"label\": \"music\" if pred_idx == 1 else \"not-music\",\n",
    "                \"confidence\": round(prob, 4),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        chunk_idx += 1\n",
    "\n",
    "        # --- DISPLAY PERCENTAGE UPDATE ---\n",
    "        if (chunk_idx % 20 == 0) or (chunk_idx == total_chunks):\n",
    "            percent = int((chunk_idx / total_chunks) * 100)\n",
    "            # Limits display to 100% and prints on one line\n",
    "            print_status(\n",
    "                f\"Generating Music Timeline: {min(100, percent):>3}% complete\"\n",
    "            )\n",
    "\n",
    "    process.terminate()\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def _get_duration(file_path):\n",
    "    cmd = [\n",
    "        \"ffprobe\",\n",
    "        \"-v\",\n",
    "        \"error\",\n",
    "        \"-show_entries\",\n",
    "        \"format=duration\",\n",
    "        \"-of\",\n",
    "        \"default=noprint_wrappers=1:nokey=1\",\n",
    "        file_path,\n",
    "    ]\n",
    "    return float(subprocess.check_output(cmd))\n",
    "\n",
    "\n",
    "def extract_music_blocks(df, min_duration_sec=120, max_gap_seconds=15):\n",
    "    print_status(\"Extracting music blocks...\")\n",
    "    \n",
    "    # Create a copy so we don't overwrite the original dataframe\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # 1. Convert to numeric for processing\n",
    "    df_clean[\"is_music\"] = df_clean[\"label\"].map({\"music\": 1, \"not-music\": 0})\n",
    "\n",
    "    # 2. SMOOTHING: Median filter - requires at least 2/3 chunks to match.\n",
    "    df_clean[\"is_music\"] = (\n",
    "        df_clean[\"is_music\"]\n",
    "        .rolling(window=3, center=True)\n",
    "        .median()\n",
    "        .fillna(df_clean[\"is_music\"])\n",
    "    )\n",
    "\n",
    "    # 3. BRIDGE GAPS: check if music exists within the 'max_gap' range\n",
    "    # Treat \"not-music\" sections as \"music\" if shorter than max_gap_seconds,\n",
    "    gap_chunks = max_gap_seconds // CLIP_SIZE\n",
    "    df_clean[\"is_music\"] = (\n",
    "        df_clean[\"is_music\"]\n",
    "        .rolling(window=gap_chunks, center=True, min_periods=1)\n",
    "        .max()\n",
    "    )\n",
    "\n",
    "    # 4. Identify song blocks using cumsum logic\n",
    "    df_clean[\"block_id\"] = (\n",
    "        df_clean[\"is_music\"] != df_clean[\"is_music\"].shift()\n",
    "    ).cumsum()\n",
    "\n",
    "    # 5. Group and Aggregate\n",
    "    blocks = df_clean.groupby(\"block_id\").agg(\n",
    "        {\"is_music\": \"first\", \"start_sec\": \"min\", \"end_sec\": \"max\"}\n",
    "    )\n",
    "\n",
    "    blocks[\"duration\"] = blocks[\"end_sec\"] - blocks[\"start_sec\"]\n",
    "\n",
    "    # 6. Filter by music label (1) and min_duration threshold\n",
    "    songs = blocks[\n",
    "        (blocks[\"is_music\"] == 1) & (blocks[\"duration\"] >= min_duration_sec)\n",
    "    ].copy()\n",
    "\n",
    "    # Formatting helper\n",
    "    def format_time(seconds):\n",
    "        return f\"{int(seconds // 60):02d}:{int(seconds % 60):02d}\"\n",
    "\n",
    "    songs[\"start_timestamp\"] = songs[\"start_sec\"].apply(format_time)\n",
    "    songs[\"end_timestamp\"] = songs[\"end_sec\"].apply(format_time)\n",
    "\n",
    "    songs = songs.reset_index()  # moves block_id from index to column\n",
    "\n",
    "    return songs[\n",
    "        [\n",
    "            \"block_id\",\n",
    "            \"start_timestamp\",\n",
    "            \"end_timestamp\",\n",
    "            \"start_sec\",\n",
    "            \"end_sec\",\n",
    "            \"duration\",\n",
    "        ]\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ac3816",
   "metadata": {},
   "source": [
    "## Get Music Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9609710",
   "metadata": {},
   "source": [
    "Generate music timeline as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca87d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(MODELS_DIR / MODEL_FILENAME)\n",
    "\n",
    "# Get music predictions timeline\n",
    "file_path = OUTPUT_AUDIO\n",
    "df = generate_music_timeline(file_path=file_path, window_sec=CLIP_SIZE, model=model)\n",
    "\n",
    "print(\"\\nHere are first few rows..\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d7d4c3",
   "metadata": {},
   "source": [
    "Show music timeline on a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58d35a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plot_path = RESULTS_DIR / \"music_timeline_plot.png\"\n",
    "plot_music_blocks(df=df, save_plot_path=save_plot_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be57224f",
   "metadata": {},
   "source": [
    "Extract music blocks from the timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc59e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_blocks = extract_music_blocks(df, min_duration_sec=120, max_gap_seconds=15)\n",
    "music_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a2b076",
   "metadata": {},
   "source": [
    "Save music_blocks to results directory as csv (overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a39d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_blocks.to_csv(RESULTS_DIR / \"music_blocks.csv\", index=False)\n",
    "print(f\"Summary saved to {RESULTS_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
